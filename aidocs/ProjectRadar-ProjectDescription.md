# **Project Description**

Version: 1.2  
Date: July 26, 2025

## **1\. Project Vision**

"Project Radar" is a specialized platform for capturing, evaluating, and tracking project opportunities for freelancers and contractors. The system automates the collection and analysis of potential projects from various sources, evaluates them using an AI-powered pipeline based on a personal user profile, and presents them in an interactive Kanban-style interface for managing the acquisition process. The goal is to drastically reduce the manual effort involved in searching for projects and to enable focus on the most relevant and suitable opportunities.

## **2\. Functional Requirements (Core Scope)**

### **2.1. Opportunity Ingestion**

Initially, a new opportunity can only be captured via a manual user interface.

* **Input UI:** A simple form with two fields:  
  1. **Source:** A text field for entering a URL or another traceable source description (e.g., "Recommendation from John Doe via email").  
  2. **Raw Data:** A large text field where the complete, unformatted "text junk" of the opportunity (e.g., text copied from an email or website, including HTML/Markdown) is pasted.

### **2.2. AI-Powered Pipeline**

After manual entry, each opportunity goes through a server-side, message-driven pipeline.

#### **2.2.1. User Profile as AI Input**

The AI uses a user-defined profile to perform the evaluation (weighting).

* **Format:** The profile consists of unstructured plain text data.  
  * One or more PDF documents (e.g., CVs) containing skills and project history.  
  * A free-text description of current preferences (e.g., "Looking for remote projects in the .NET environment, minimum 6 months duration, no financial industry").

#### **2.2.2. Data Extraction**

A Large Language Model (LLM) analyzes the raw text data and extracts structured information.

* **Data Schema:** The schema for the extracted data should be flexible and extensible. An initial list of fields to be extracted includes:  
  * Project Title, Customer Name, Name of the recruitment agency (if any), Location, Project Duration, Share of remote work, Offered rate/hourly rate, Estimated scope (e.g., in person-days), Contact person (agency/customer), List of required hard and soft skills.  
* **Filterability:** The extracted data forms the basis for later filter functions in the UI.

#### **2.2.3. AI Weighting**

The LLM compares the extracted opportunity data with the user profile.

* **Score:** The result is a numerical score from 1 to 100\.  
* **Justification:** In addition to the score, the AI generates a brief textual justification for the rating.  
* **Audit Trail:** All results generated by the AI are versioned and stored in a traceable manner.

#### **2.2.4. Deduplication**

The system should detect duplicates.

* **Mechanism:** Deduplication is performed using a hash generated from the core data of the extracted opportunity.

### **2.3. User Interface & Workflow**

The user interface is divided into three main areas: **Inbox**, **Backlog**, and **Active (Kanban Board)**.

#### **2.3.1. Inbox**

* **Purpose:** Serves as the entry point for all new opportunities.  
* **Actions:** Move to backlog or archive.

#### **2.3.2. Backlog**

* **Purpose:** A collection of interesting opportunities.  
* **Sorting:** Initially by AI score, manual prioritization via drag-and-drop.  
* **Actions:** Start acquisition or archive.

#### **2.3.3. Active (Kanban Board)**

* **Purpose:** Active tracking of the acquisition pipeline.  
* **Workflow:** Drag-and-drop between status columns (e.g., "New", "Contacted", "Proposal").  
* **End States:** "Won" or "Lost".

#### **2.3.4. General UI Functions**

* **Data Editing:** All data related to an opportunity must be manually editable at all stages of the process.  
* **Detail View:** Displays all information about a selected opportunity.

## **3\. Non-Functional Requirements**

### **3.1. Architecture**

* **Style:** Reactive, message-driven microservice architecture.  
* **Communication:** Asynchronous via a message bus.  
* **Microservices (Examples):** Small, focused services (Identifier, Validation, Enrichment, Deduplication, Weighting).

### **3.2. Persistence & State Management**

* **Foundation:** Event Sourcing and CQRS.  
* **Event Store:** Development of a custom Event Store following the **"Aggregateless Event Sourcing"** pattern with **"Command Context Consistency"**.  
* **Database:** PostgreSQL for the event store and the read models.

### **3.3. Technology Stack**

* **Backend:** .NET 8  
* **Message Bus:** RabbitMQ  
* **Frontend:** Prototyping with Next.js, final implementation with Blazor WebAssembly.  
* **LLM:** Connection via an abstraction layer.

### **3.4. Infrastructure**

* **Containerization:** All services of the application will be operated in Docker containers.

### **3.5. Authentication & Authorization**

* **Standard:** The application must be developed as "production-ready" from the start.  
* **Mechanism:** An OAuth 2.0 / OpenID Connect flow will be implemented for user authentication and authorization.

### **3.6. Diagnosability**

* **Logging:** Structured logging will be implemented throughout using **Serilog**.  
* **Audit Trails & Replayability:** The event sourcing architecture and messaging will be used to ensure complete and traceable audit trails for all state changes. This allows for the complete reconstruction of the system state at any point in time (Replayability).
* **OpenTelemetry traces & metrics** exported to Grafana Tempo/Prometheus.
* **Serilog sinks:** OTLP

### 3.7 Security Notes
* **Authentication:** OAuth 2.0/OIDC via **Auth0**.
* **CSRF:** Handled by using only bearer‑token auth; cookies flagged `SameSite=None; Secure`.
* **Secrets:** Managed as Docker Secrets (no plain‑text env files committed).

### 3.8 Fuzzy Deduplication
A future service will use a **MinHash + Jaccard Similarity** algorithm with configurable 3‑ to 5‑gram shingles to detect near‑duplicates.  Implementation initially in Python (`datasketch`), callable from .NET via gRPC.

## **4\. Process & Quality Assurance**

### **4.1. CI/CD Pipeline**

* **Platform:** A CI/CD pipeline will be set up from the beginning using **GitHub Actions**.  
* **Goals:**  
  * **Continuous Integration:** Every push to the main branch automatically triggers a build, test execution, and static code analysis.  
  * **Continuous Deployment:** Successful builds of the main branch should potentially be deployed automatically to a staging or production environment. The exact deployment concept for containers is yet to be developed.

### **4.2. Quality Metrics & Quality Gates**

* **Unit Tests:** Unit tests will be created for new and modified logic.  
  * **Code Coverage:** A code coverage of \>80% (to be finalized) is targeted as a quality goal.  
* **Static Code Analysis:**  
  * Metrics such as **cyclomatic complexity** and other common metrics will be collected to monitor code quality.  
  * **Linter:** The code will be automatically checked for style and potential sources of error.  
* **Quality Gates:** The CI pipeline will be configured so that a merge into the main branch is only possible if all quality gates (tests, coverage, linter, static analysis) have been passed successfully.

### **4.3. Project Tracking Metrics**

* **Code Volume:** To quantify project progress, metrics on code volume will be collected.  
* **Tool:** The command-line tool cloc (Count Lines of Code) will be used.  
* **Implementation:** A **pre-commit hook** will be set up to run cloc before each commit and save the statistics in a versioned file (e.g., CSV).  
* **Brainstorming on collected metrics:**  
  * files: Number of files per language (C\#, TypeScript, etc.).  
  * code: Number of pure code lines.  
  * comment: Number of comment lines to measure documentation density.  
  * blank: Number of blank lines.  
  * **Analysis:** This data enables a quantitative analysis of project growth, the distribution of work between frontend/backend, and the documentation effort over time.

## **5\. Delimitation (Out of Scope)**

* **No Automatic Crawlers:** The only input method is the manual UI.  
* **No CRM:** No advanced management of contacts or communication histories.  
* **No Social Media Functions:** No integrations or public project features.

## **6\. Open Points & Questions to be Clarified**

* **Functional/Technical:**  
  * Final schema of the extracted data.  
  * Final deduplication algorithm.  
  * Final Kanban board columns (possibly configurable).  
  * Design of the detail view.  
  * Exact cut of the microservices.  
  * Choice of the LLM provider.  
* **Process/Quality:**  
  * Final definition of the code coverage targets.  
  * Selection of specific metrics for static code analysis.  
  * Detailed concept for the automated deployment of the containers.
* **Event retention policy** (see Architecture §5.3).
* **Container hardening baseline (CIS) & SBOM publishing.**